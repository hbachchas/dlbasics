{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules imported\n"
     ]
    }
   ],
   "source": [
    "# Triplet siamese net model\n",
    "\n",
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "print('modules imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "pos files:  10750\n",
      "neg files:  10750\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print('Loading dataset...')\n",
    "from load_tuple_verification_datasets import load_dataset_RGB\n",
    "X1_train, X2_train, X3_train, y_train, X1_test, X2_test, X3_test, y_test = load_dataset_RGB()\n",
    "print('Dataset loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X1_train.shape)\n",
    "import cv2\n",
    "cv2.imshow(\"Image X1\", X1_train[2,:,:,:])\n",
    "cv2.imshow(\"Image X2\", X2_train[2,:,:,:])\n",
    "cv2.imshow(\"Image X3\", X3_train[2,:,:,:])\n",
    "print(y_train[3])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "im  = cv2.read('/home/himanshu/Pictures/1.jpg')\n",
    "cv2.imshow(\"Image X3\", im)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the vision modules\n",
    "\n",
    "s_input = Input(shape=(96, 128, 3))\n",
    "# x = Conv2D(64, (3, 3), padding='same', kernel_constraint=maxnorm(3))(s_input)\n",
    "x = Conv2D(64, (3, 3), padding='same', kernel_constraint=maxnorm(3))(s_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(96, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3))(x)\n",
    "x = Conv2D(96, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1048, activation='relu', kernel_constraint=maxnorm(3))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1048, activation='relu', kernel_constraint=maxnorm(3))(x)\n",
    "out = Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_model = Model(s_input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then define the tell-digits-apart model\n",
    "s_a = Input(shape=(96, 128, 3))\n",
    "s_b = Input(shape=(96, 128, 3))\n",
    "s_c = Input(shape=(96, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vision model will be shared, weights and all\n",
    "out_a = vision_model(s_a)\n",
    "out_b = vision_model(s_b)\n",
    "out_c = vision_model(s_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "concatenated = keras.layers.concatenate([out_a, out_b, out_c])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = Model([s_a, s_b, s_c], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 96, 128, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 96, 128, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 96, 128, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 1048)         27292400    input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3144)         0           model_5[1][0]                    \n",
      "                                                                 model_5[2][0]                    \n",
      "                                                                 model_5[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            3145        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 27,295,545\n",
      "Trainable params: 27,295,097\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "\n",
    "epochs = 30\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "classification_model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(classification_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17200 samples, validate on 4300 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,96,128,64]\n\t [[Node: model_5_1/conv2d_22/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_5_1/activation_3/Relu, conv2d_22/kernel/read)]]\n\t [[Node: metrics_4/acc/Mean_1/_1025 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3561_metrics_4/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'model_5_1/conv2d_22/convolution', defined at:\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-1096540f3a57>\", line 3, in <module>\n    out_b = vision_model(s_b)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/engine/topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/engine/topology.py\", line 2236, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 3335, in conv2d\n    data_format=tf_data_format)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,96,128,64]\n\t [[Node: model_5_1/conv2d_22/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_5_1/activation_3/Relu, conv2d_22/kernel/read)]]\n\t [[Node: metrics_4/acc/Mean_1/_1025 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3561_metrics_4/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,96,128,64]\n\t [[Node: model_5_1/conv2d_22/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_5_1/activation_3/Relu, conv2d_22/kernel/read)]]\n\t [[Node: metrics_4/acc/Mean_1/_1025 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3561_metrics_4/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4b22d0322988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcsv_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./evaluation/log.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX3_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX3_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,96,128,64]\n\t [[Node: model_5_1/conv2d_22/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_5_1/activation_3/Relu, conv2d_22/kernel/read)]]\n\t [[Node: metrics_4/acc/Mean_1/_1025 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3561_metrics_4/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'model_5_1/conv2d_22/convolution', defined at:\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-25-1096540f3a57>\", line 3, in <module>\n    out_b = vision_model(s_b)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/engine/topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/engine/topology.py\", line 2236, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 3335, in conv2d\n    data_format=tf_data_format)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/himanshu/Installed/anaconda/anaconda3/anaconda/envs/e1_dl_py3.5/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,96,128,64]\n\t [[Node: model_5_1/conv2d_22/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model_5_1/activation_3/Relu, conv2d_22/kernel/read)]]\n\t [[Node: metrics_4/acc/Mean_1/_1025 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3561_metrics_4/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger('./evaluation/log.csv', append=True, separator=';')\n",
    "\n",
    "history = classification_model.fit([X1_train, X2_train, X3_train], y_train, validation_data=([X1_test, X2_test, X3_test], y_test), epochs=epochs, batch_size=8, verbose=1, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model architecture and weights\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = classification_model.to_json()\n",
    "with open(\"./evaluation/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "classification_model.save_weights(\"./evaluation/model.h5\")\n",
    "print(\"Model saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "\n",
    "scores = classification_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training progress     # keep verbose=1 in model.fit()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, draw\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "plt.savefig('./evaluation/Acc.eps', format='eps', dpi=400)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower left')\n",
    "# plt.show()\n",
    "plt.savefig('./evaluation/Loss.eps', format='eps', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_a = Input(shape=(280, 256))\n",
    "tweet_b = Input(shape=(280, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This layer can take as input a matrix\n",
    "# and will return a vector of size 64\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "# When we reuse the same layer instance\n",
    "# multiple times, the weights of the layer\n",
    "# are also being reused\n",
    "# (it is effectively *the same* layer)\n",
    "encoded_a = shared_lstm(tweet_a)\n",
    "encoded_b = shared_lstm(tweet_b)\n",
    "\n",
    "# We can then concatenate the two vectors:\n",
    "merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)\n",
    "\n",
    "# And add a logistic regression on top\n",
    "predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "# We define a trainable model linking the\n",
    "# tweet inputs to the predictions\n",
    "model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([data_a, data_b], labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# First, define the vision modules\n",
    "digit_input = Input(shape=(27, 27, 1))\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)\n",
    "\n",
    "vision_model = Model(digit_input, out)\n",
    "\n",
    "# Then define the tell-digits-apart model\n",
    "digit_a = Input(shape=(27, 27, 1))\n",
    "digit_b = Input(shape=(27, 27, 1))\n",
    "\n",
    "# The vision model will be shared, weights and all\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = keras.layers.concatenate([out_a, out_b])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
